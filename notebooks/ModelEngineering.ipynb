{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Engineering - Art Auction Price Prediction\n",
    "## ML Pipeline for Training and Evaluating Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlflow scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ MLflow Version: 3.4.0\n",
      "‚úì Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üîÑ MLflow Version:\", mlflow.__version__)\n",
    "print(\"‚úì Libraries imported successfully\")\n",
    "\n",
    "models_dir = \"../models/\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "final_df = pd.read_csv('../data/processed/final_art_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values, standardizing numerical features, and encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Handling Missing Target Values\n",
      "Initial number of records: 754\n",
      "Records with missing prices: 0\n",
      "Records available for training: 754\n",
      "Records saved for inference: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Remove records with missing prices\n",
    "# Since price_usd is our target variable, we cannot use records without prices for training\n",
    "print(\"\\nHandling Missing Target Values\")\n",
    "print(f\"Initial number of records: {len(final_df)}\")\n",
    "\n",
    "# Check for missing prices\n",
    "missing_prices = final_df['price_usd'].isnull().sum()\n",
    "print(f\"Records with missing prices: {missing_prices}\")\n",
    "\n",
    "# Remove records with missing prices for training data\n",
    "train_df = final_df.dropna(subset=['price_usd']).copy()\n",
    "print(f\"Records available for training: {len(train_df)}\")\n",
    "\n",
    "# Save records with missing prices for future inference/prediction\n",
    "inference_df = final_df[final_df['price_usd'].isnull()].copy()\n",
    "print(f\"Records saved for inference: {len(inference_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing Features and Target Variable\n",
      "Features shape: (754, 13)\n",
      "Target variable shape: (754,)\n",
      "\n",
      "Feature summary:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 754 entries, 0 to 753\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   artist_id          296 non-null    float64\n",
      " 1   artist             753 non-null    object \n",
      " 2   title              754 non-null    object \n",
      " 3   creation_year      725 non-null    float64\n",
      " 4   period             753 non-null    object \n",
      " 5   movement           754 non-null    object \n",
      " 6   size_category      458 non-null    object \n",
      " 7   avg_dimension_cm   458 non-null    float64\n",
      " 8   lifespan           1 non-null      float64\n",
      " 9   years_since_death  1 non-null      float64\n",
      " 10  paintings          1 non-null      float64\n",
      " 11  signed_binary      754 non-null    int64  \n",
      " 12  is_living          1 non-null      object \n",
      "dtypes: float64(6), int64(1), object(6)\n",
      "memory usage: 76.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Separate features and target variable\n",
    "print(\"\\nPreparing Features and Target Variable\")\n",
    "\n",
    "X = train_df.drop('price_usd', axis=1)  # Features\n",
    "y = train_df['price_usd']               # Target variable\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target variable shape: {y.shape}\")\n",
    "\n",
    "# Display feature summary\n",
    "print(\"\\nFeature summary:\")\n",
    "print(X.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Defining Feature Types with Missing Value Analysis\n",
      "Feature availability analysis:\n",
      "  artist_id: 296/754 (39.3%) - float64\n",
      "  artist: 753/754 (99.9%) - object\n",
      "  title: 754/754 (100.0%) - object\n",
      "  creation_year: 725/754 (96.2%) - float64\n",
      "  period: 753/754 (99.9%) - object\n",
      "  movement: 754/754 (100.0%) - object\n",
      "  size_category: 458/754 (60.7%) - object\n",
      "  avg_dimension_cm: 458/754 (60.7%) - float64\n",
      "  lifespan: 1/754 (0.1%) - float64\n",
      "  years_since_death: 1/754 (0.1%) - float64\n",
      "  paintings: 1/754 (0.1%) - float64\n",
      "  signed_binary: 754/754 (100.0%) - int64\n",
      "  is_living: 1/754 (0.1%) - object\n",
      "\n",
      "Usable numerical features (0): []\n",
      "Usable categorical features (3): ['period', 'movement', 'size_category']\n",
      "‚úì Sufficient features available for modeling\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define feature types for preprocessing with proper missing value analysis\n",
    "print(\"\\nStep 3: Defining Feature Types with Missing Value Analysis\")\n",
    "\n",
    "# First, let's analyze the actual availability of each feature\n",
    "print(\"Feature availability analysis:\")\n",
    "feature_analysis = []\n",
    "for feature in X.columns:\n",
    "    non_null_count = X[feature].notnull().sum()\n",
    "    non_null_pct = (non_null_count / len(X)) * 100\n",
    "    feature_analysis.append({\n",
    "        'feature': feature,\n",
    "        'non_null_count': non_null_count,\n",
    "        'non_null_pct': non_null_pct,\n",
    "        'dtype': X[feature].dtype\n",
    "    })\n",
    "    print(f\"  {feature}: {non_null_count}/{len(X)} ({non_null_pct:.1f}%) - {X[feature].dtype}\")\n",
    "\n",
    "feature_analysis_df = pd.DataFrame(feature_analysis)\n",
    "\n",
    "# Select features with sufficient data (>50% non-null values)\n",
    "usable_numeric_features = feature_analysis_df[\n",
    "    (feature_analysis_df['dtype'].isin(['float64', 'int64'])) & \n",
    "    (feature_analysis_df['non_null_pct'] > 50)\n",
    "]['feature'].tolist()\n",
    "\n",
    "usable_categorical_features = feature_analysis_df[\n",
    "    (feature_analysis_df['dtype'] == 'object') & \n",
    "    (feature_analysis_df['non_null_pct'] > 50)\n",
    "]['feature'].tolist()\n",
    "\n",
    "# Remove identifier features from modeling features\n",
    "identifier_features = ['artist_id', 'artist', 'title']\n",
    "modeling_numeric_features = [f for f in usable_numeric_features if f not in identifier_features]\n",
    "modeling_categorical_features = [f for f in usable_categorical_features if f not in identifier_features]\n",
    "\n",
    "print(f\"\\nUsable numerical features ({len(modeling_numeric_features)}): {modeling_numeric_features}\")\n",
    "print(f\"Usable categorical features ({len(modeling_categorical_features)}): {modeling_categorical_features}\")\n",
    "\n",
    "# Check if we have enough features to proceed\n",
    "if len(modeling_numeric_features) == 0 and len(modeling_categorical_features) == 0:\n",
    "    print(\"‚ùå ERROR: No usable features found for modeling!\")\n",
    "else:\n",
    "    print(\"‚úì Sufficient features available for modeling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Preprocessing Pipelines for Available Features\n",
      "No numerical features available - numerical transformer set to 'drop'\n",
      "Categorical transformer created for 3 features\n",
      "‚úì Preprocessing pipeline created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Create preprocessing pipelines for available features\n",
    "print(\"\\nCreating Preprocessing Pipelines for Available Features\")\n",
    "\n",
    "if len(modeling_numeric_features) > 0:\n",
    "    # Numerical pipeline for features with sufficient data\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    print(f\"Numerical transformer created for {len(modeling_numeric_features)} features\")\n",
    "else:\n",
    "    numeric_transformer = 'drop'\n",
    "    print(\"No numerical features available - numerical transformer set to 'drop'\")\n",
    "\n",
    "if len(modeling_categorical_features) > 0:\n",
    "    # Categorical pipeline for features with sufficient data\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first'))\n",
    "    ])\n",
    "    print(f\"Categorical transformer created for {len(modeling_categorical_features)} features\")\n",
    "else:\n",
    "    categorical_transformer = 'drop'\n",
    "    print(\"No categorical features available - categorical transformer set to 'drop'\")\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, modeling_numeric_features),\n",
    "        ('cat', categorical_transformer, modeling_categorical_features)\n",
    "    ],\n",
    "    remainder='drop'  # Drop features not used in modeling\n",
    ")\n",
    "\n",
    "print(\"‚úì Preprocessing pipeline created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying Preprocessing Transformations\n",
      "Original number of features: 13\n",
      "Number of features after preprocessing: 37\n",
      "Processed features shape: (754, 37)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Apply preprocessing transformations\n",
    "print(\"\\nApplying Preprocessing Transformations\")\n",
    "\n",
    "try:\n",
    "    # Fit and transform the features\n",
    "    X_processed = preprocessor.fit_transform(X)\n",
    "    \n",
    "    # Get feature names after preprocessing\n",
    "    feature_names = []\n",
    "    \n",
    "    if len(modeling_numeric_features) > 0:\n",
    "        feature_names.extend(modeling_numeric_features)\n",
    "    \n",
    "    if len(modeling_categorical_features) > 0:\n",
    "        cat_transformer = preprocessor.named_transformers_['cat']\n",
    "        cat_feature_names = cat_transformer.named_steps['onehot'].get_feature_names_out(modeling_categorical_features)\n",
    "        feature_names.extend(cat_feature_names)\n",
    "    \n",
    "    print(f\"Original number of features: {X.shape[1]}\")\n",
    "    print(f\"Number of features after preprocessing: {len(feature_names)}\")\n",
    "    print(f\"Processed features shape: {X_processed.shape}\")\n",
    "    \n",
    "    if X_processed.shape[1] == 0:\n",
    "        print(\"‚ùå WARNING: No features were produced after preprocessing!\")\n",
    "        print(\"This usually happens when most features have too many missing values.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during preprocessing: {e}\")\n",
    "    print(\"This is likely due to insufficient data in the features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize MLflow Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLflow Experiment: Art_Auction_Price_Prediction\n",
      "‚úì Experiment configured successfully\n"
     ]
    }
   ],
   "source": [
    "# Set MLflow tracking URI and experiment name\n",
    "mlflow.set_tracking_uri(\"file:../models/mlruns\")\n",
    "mlflow.set_experiment(\"Art_Auction_Price_Prediction\")\n",
    "\n",
    "print(\"\\nMLflow Experiment: Art_Auction_Price_Prediction\")\n",
    "print(\"‚úì Experiment configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Splitting data into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting Data into Training and Testing Sets\n",
      "‚úì Training set: (603, 37) features, (603,) target\n",
      "‚úì Testing set: (151, 37) features, (151,) target\n",
      "‚úì Train/Test split: 603/151 records\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSplitting Data into Training and Testing Sets\")\n",
    "\n",
    "# Create DataFrame with processed features\n",
    "X_processed_df = pd.DataFrame(X_processed, columns=feature_names)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed_df, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"‚úì Training set: {X_train.shape} features, {y_train.shape} target\")\n",
    "print(f\"‚úì Testing set: {X_test.shape} features, {y_test.shape} target\")\n",
    "print(f\"‚úì Train/Test split: {len(X_train)}/{len(X_test)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Feature Engineering (Additional Transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transformation Rationale\n",
    "\n",
    "The logarithmic transformation (`np.log1p`) addresses the highly **right-skewed distribution** typical of art auction prices, where most artworks cluster at lower price points while a few masterpieces reach extreme values. This transformation compresses the scale, reduces the influence of outliers, and creates a more normal distribution, leading to more stable training and percentage-based error interpretation. The reverse transformation (`np.expm1`) converts predictions back to the original dollar scale while maintaining meaningful error metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Applied logarithmic transformation to target variable\n"
     ]
    }
   ],
   "source": [
    "# Apply logarithmic transformation to target variable (for skewed price distribution)\n",
    "y_train_log = np.log1p(y_train)  # log(1 + y) to handle zero values\n",
    "y_test_log = np.log1p(y_test)\n",
    "\n",
    "print(\"‚úì Applied logarithmic transformation to target variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Model Training with MLflow Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection Justification\n",
    "\n",
    "The **Random Forest Regressor** was chosen for its robustness against overfitting and ability to capture complex non-linear relationships in art pricing data, which often involves intricate interactions between artist reputation, artwork characteristics, and market trends. The **Linear Regression** serves as a simple baseline model to benchmark performance against more complex algorithms. Both models handle the log-transformed target variable effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training RandomForest ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/24 05:50:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/24 05:50:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RandomForest trained successfully\n",
      "   MAE: $160.59\n",
      "   RMSE: $327.93\n",
      "   R¬≤ Score: -0.1412\n",
      "\n",
      "--- Training LinearRegression ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/24 05:51:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/24 05:51:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LinearRegression trained successfully\n",
      "   MAE: $159.12\n",
      "   RMSE: $327.89\n",
      "   R¬≤ Score: -0.1410\n",
      "\n",
      "Best Model: LinearRegression with RMSE: $327.89\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10),\n",
    "    \"LinearRegression\": LinearRegression()\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_score = float('inf')\n",
    "best_model_name = \"\"\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n--- Training {model_name} ---\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        model.fit(X_train, y_train_log)\n",
    "        \n",
    "        # Make predictions (convert back from log scale)\n",
    "        y_pred_log = model.predict(X_test)\n",
    "        y_pred = np.expm1(y_pred_log)  # Reverse log transformation\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        cv_scores = cross_val_score(model, X_train, y_train_log, \n",
    "                                  cv=5, scoring='neg_mean_squared_error')\n",
    "        cv_rmse = np.sqrt(-cv_scores.mean())\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        if model_name == \"RandomForest\":\n",
    "            mlflow.log_param(\"n_estimators\", 100)\n",
    "            mlflow.log_param(\"max_depth\", 10)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"cv_rmse\", cv_rmse)\n",
    "        \n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(model, f\"{model_name.lower()}_model\")\n",
    "        \n",
    "        # Log feature importance for RandomForest\n",
    "        if model_name == \"RandomForest\":\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': X_train.columns,\n",
    "                'importance': model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            # Save feature importance as artifact\n",
    "            feature_importance.to_csv(f\"{model_name}_feature_importance.csv\", index=False)\n",
    "            mlflow.log_artifact(f\"{model_name}_feature_importance.csv\")\n",
    "        \n",
    "        print(f\"‚úÖ {model_name} trained successfully\")\n",
    "        print(f\"   MAE: ${mae:,.2f}\")\n",
    "        print(f\"   RMSE: ${rmse:,.2f}\")\n",
    "        print(f\"   R¬≤ Score: {r2:.4f}\")\n",
    "        \n",
    "        if rmse < best_score:\n",
    "            best_score = rmse\n",
    "            best_model = model\n",
    "            best_model_name = model_name\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name} with RMSE: ${best_score:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Model Packaging and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Packaging and Saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/24 05:51:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/24 05:51:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Best model saved as: ../models/art_auction_price_model_linearregression.pkl\n",
      "‚úì Model logged to MLflow tracking server\n",
      "‚úì Model metadata saved and logged\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel Packaging and Saving\")\n",
    "\n",
    "# Save the best model as the final artifact\n",
    "if best_model is not None:\n",
    "    # Save using MLflow\n",
    "    with mlflow.start_run(run_name=\"Final_Model\"):\n",
    "        mlflow.log_param(\"best_model\", best_model_name)\n",
    "        mlflow.log_metric(\"best_rmse\", best_score)\n",
    "        \n",
    "        # Log the best model\n",
    "        mlflow.sklearn.log_model(best_model, \"final_model\")\n",
    "        \n",
    "        # Also save using joblib for easy access\n",
    "        import joblib\n",
    "        model_filename = f\"art_auction_price_model_{best_model_name.lower()}.pkl\"\n",
    "        model_filepath = os.path.join(models_dir, model_filename)\n",
    "        joblib.dump(best_model, model_filepath)\n",
    "        \n",
    "        # Log the file as artifact\n",
    "        mlflow.log_artifact(model_filepath)\n",
    "        \n",
    "        print(f\"‚úì Best model saved as: {model_filepath}\")\n",
    "        print(\"‚úì Model logged to MLflow tracking server\")\n",
    "        \n",
    "        model_metadata = {\n",
    "            \"model_name\": best_model_name,\n",
    "            \"training_date\": pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            \"features_used\": list(X_train.columns),\n",
    "            \"performance_metrics\": {\n",
    "                \"rmse\": float(best_score),\n",
    "                \"r2_score\": float(r2_score(y_test, np.expm1(best_model.predict(X_test))))\n",
    "            },\n",
    "            \"data_dimensions\": {\n",
    "                \"training_samples\": X_train.shape[0],\n",
    "                \"features_count\": X_train.shape[1],\n",
    "                \"test_samples\": X_test.shape[0]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        metadata_filepath = os.path.join(models_dir, \"model_metadata.json\")\n",
    "        with open(metadata_filepath, 'w') as f:\n",
    "            json.dump(model_metadata, f, indent=2)\n",
    "        \n",
    "        mlflow.log_artifact(metadata_filepath)\n",
    "        print(\"‚úì Model metadata saved and logged\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No model was trained successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Performance Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Analysis\n",
      "‚úì Prediction results saved: ../models/model_predictions.csv\n",
      "\n",
      "Final Model Performance (LinearRegression):\n",
      "Mean Absolute Error: $159.12\n",
      "Median Absolute Error: $20.00\n",
      "Max Absolute Error: $963.89\n",
      "Mean Percentage Error: 568.45%\n",
      "\n",
      "Sample Predictions:\n",
      "Actual: $1.50 | Predicted: $42.08 | Error: $40.58\n",
      "Actual: $9.50 | Predicted: $22.50 | Error: $13.00\n",
      "Actual: $1.27 | Predicted: $19.96 | Error: $18.68\n",
      "Actual: $2.50 | Predicted: $22.50 | Error: $20.00\n",
      "Actual: $13.00 | Predicted: $9.30 | Error: $3.70\n",
      "Actual: $4.00 | Predicted: $4.00 | Error: $0.00\n",
      "Actual: $680.00 | Predicted: $22.50 | Error: $657.50\n",
      "Actual: $1.50 | Predicted: $42.08 | Error: $40.58\n",
      "Actual: $1.50 | Predicted: $17.70 | Error: $16.20\n",
      "Actual: $680.00 | Predicted: $8.19 | Error: $671.81\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel Performance Analysis\")\n",
    "\n",
    "if best_model is not None:\n",
    "    y_pred_log = best_model.predict(X_test)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "        'actual_price': y_test.values,\n",
    "        'predicted_price': y_pred,\n",
    "        'absolute_error': np.abs(y_test.values - y_pred),\n",
    "        'percentage_error': (np.abs(y_test.values - y_pred) / y_test.values) * 100\n",
    "    })\n",
    "    \n",
    "    results_filepath = os.path.join(models_dir, \"model_predictions.csv\")\n",
    "    results_df.to_csv(results_filepath, index=False)\n",
    "    mlflow.log_artifact(results_filepath)\n",
    "    \n",
    "    print(f\"‚úì Prediction results saved: {results_filepath}\")\n",
    "    print(f\"\\nFinal Model Performance ({best_model_name}):\")\n",
    "    print(f\"Mean Absolute Error: ${results_df['absolute_error'].mean():,.2f}\")\n",
    "    print(f\"Median Absolute Error: ${results_df['absolute_error'].median():,.2f}\")\n",
    "    print(f\"Max Absolute Error: ${results_df['absolute_error'].max():,.2f}\")\n",
    "    print(f\"Mean Percentage Error: {results_df['percentage_error'].mean():.2f}%\")\n",
    "    \n",
    "    # Sample predictions\n",
    "    print(f\"\\nSample Predictions:\")\n",
    "    sample_results = results_df.head(10).copy()\n",
    "    for idx, row in sample_results.iterrows():\n",
    "        print(f\"Actual: ${row['actual_price']:,.2f} | Predicted: ${row['predicted_price']:,.2f} | Error: ${row['absolute_error']:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: MLflow Experiment Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLflow Experiment Summary\n",
      "Experiment ID: 822850360807149285\n",
      "Artifact Location: file:///c:/Users/User/Desktop/Forecasting-auction-prices-for-artworks/notebooks/../models/mlruns/822850360807149285\n",
      "\n",
      "Total runs in experiment: 4\n",
      "Recent runs:\n",
      "                          run_id  tags.mlflow.runName  metrics.rmse  metrics.r2\n",
      "780ca74a722d4a5295d174503adbd974 adventurous-slug-729           NaN         NaN\n",
      "01431042e8704917937e2d09ebb11b01          Final_Model           NaN         NaN\n",
      "5a8e0e68f26c4a26a0f299b8dbf35b13     LinearRegression    327.887343   -0.140985\n",
      "59717f59028f4a469902895b9743a6d3         RandomForest    327.925227   -0.141249\n",
      "\n",
      "Model Engineering Completed Successfully!\n",
      "Generated Artifacts:\n",
      "  - Trained model files (.pkl)\n",
      "  - Model metadata (model_metadata.json)\n",
      "  - Prediction results (model_predictions.csv)\n",
      "  - Feature importance analysis\n",
      "  - MLflow experiment tracking data\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMLflow Experiment Summary\")\n",
    "\n",
    "# Display MLflow experiment information\n",
    "experiment = mlflow.get_experiment_by_name(\"Art_Auction_Price_Prediction\")\n",
    "if experiment:\n",
    "    print(f\"Experiment ID: {experiment.experiment_id}\")\n",
    "    print(f\"Artifact Location: {experiment.artifact_location}\")\n",
    "    \n",
    "    # List recent runs\n",
    "    runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "    if not runs.empty:\n",
    "        print(f\"\\nTotal runs in experiment: {len(runs)}\")\n",
    "        print(\"Recent runs:\")\n",
    "        recent_runs = runs[['run_id', 'tags.mlflow.runName', 'metrics.rmse', 'metrics.r2']].head()\n",
    "        print(recent_runs.to_string(index=False))\n",
    "\n",
    "print(\"\\nModel Engineering Completed Successfully!\")\n",
    "print(\"Generated Artifacts:\")\n",
    "print(\"  - Trained model files (.pkl)\")\n",
    "print(\"  - Model metadata (model_metadata.json)\")\n",
    "print(\"  - Prediction results (model_predictions.csv)\")\n",
    "print(\"  - Feature importance analysis\")\n",
    "print(\"  - MLflow experiment tracking data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
